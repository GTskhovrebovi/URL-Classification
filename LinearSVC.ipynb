{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_legitimate = pd.read_csv(\"legitimate_words.csv\", header=None, encoding = 'utf8').dropna()\n",
    "df_malicious = pd.read_csv(\"malicious_words.csv\", header=None, encoding = 'utf8').dropna()\n",
    "X_data = df_legitimate[0].tolist() + df_malicious[0].tolist()\n",
    "y_data = np.zeros(len(df_legitimate)).tolist() + np.ones(len(df_malicious)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_legitimate = pd.read_csv(\"legitimate.txt\", names=['url'], encoding = 'utf8').dropna()\n",
    "df_malicious = pd.read_csv(\"malicious.txt\",names=['url'], encoding = 'utf8').dropna()\n",
    "X_data = df_legitimate['url'].tolist() + df_malicious['url'].tolist()\n",
    "y_data = np.zeros(len(df_legitimate)).tolist() + np.ones(len(df_malicious)).tolist()\n",
    "\n",
    "#dfdf==pdpd..read_csvread_csv('smsspam',sep='\\t',names=['Status','Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_legitimate['url'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_test = CountVectorizer()\n",
    "#x_traincv_test = cv_test.fit_transform([\"Hi How are you How are you doing\",\"Hi what's up\",\"Wow that's awesome ttt/213s>2ss\"])\n",
    "#x_traincv_test.toarray()\n",
    "#cv_test.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tf_idf = TfidfVectorizer()\n",
    "x_traincv =cv.fit_transform(X_train)\n",
    "x_testcv=cv.transform(X_test)\n",
    "x_train_tf_idf =tf_idf.fit_transform(X_train)\n",
    "x_test_tf_idf=tf_idf.transform(X_test)\n",
    "\n",
    "y_train= [int(i) for i in y_train]\n",
    "y_test= [int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., '㸀㰀script㸀confirm', 'ﬁnd', 'ｅｘｐｒｅｓｓｉｏｎ'],\n",
       "      dtype='<U1026')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf_idf[0].toarray()[x_train_tf_idf[0].toarray()!=0]\n",
    "np.array(tf_idf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ｅｘｐｒｅｓｓｉｏｎ', 'alumni_off', 'aluvinmisery_vclip', 'alunos', 'alundraii', 'alundainaward', 'alumpostcards2', 'alumphoto', 'alumnos', 'alumnisociety', 'alumnisignup', 'alumniresources', 'alumnireception2006', 'alumnioff', 'alumnifriends', 'alumnicenter', 'alumni_update', 'alumni_strategy', 'alumni_smile', 'alumni_pride']\n"
     ]
    }
   ],
   "source": [
    "#top features\n",
    "indices = np.argsort(tf_idf.idf_)[::-1]\n",
    "features = tf_idf.get_feature_names()\n",
    "top_n = 20\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "print (top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753457"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "linear_svc_model = LinearSVC()\n",
    "logistic_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model.fit(x_traincv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc_model.fit(x_traincv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.fit(x_traincv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(model, X,y):\n",
    "    predictions=model.predict(X)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions, y).ravel()\n",
    "    total = tn+fp+fn+tp\n",
    "    actual_no = tn + fp\n",
    "    actual_yes = tp + fn\n",
    "\n",
    "    #print(tn, fp, fn, tp)\n",
    "    #print((tn + tp) / (tn+fp+fn+tp))\n",
    "    #print(tp / (tp + fn))\n",
    "    #print((tp + fp) / (tn+fp+fn+tp))\n",
    "    #print(tp / (tp+fp))\n",
    "    #print(tn / (tn+fn))\n",
    "    print('tn:' + str(tn), 'fp:' + str(fp))\n",
    "    print('fn:' + str(fn), 'tp:' + str(tp) +'\\n')\n",
    "    print('Accuracy: ' + str((tp+tn)*100/total))\n",
    "    print('Misclassification: ' + str((fp+fn)*100/total))\n",
    "    print('True Positive Rate: ' + str((tp)*100/actual_yes))\n",
    "    print('False Positive Rat: ' + str((fp)*100/actual_no))\n",
    "    print('Specificity: ' + str((tn)*100/actual_no))\n",
    "    print('Precision: ' + str((tp)*100/(tp+fp)))\n",
    "    print('Prevalence: ' + str(actual_yes*100/total))\n",
    "    print(tp / (tp+fp))\n",
    "    print(tn / (tn+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn:258471 fp:2079\n",
      "fn:489 tp:7260\n",
      "\n",
      "Accuracy: 99.04285889995863\n",
      "Misclassification: 0.9571411000413718\n",
      "True Positive Rate: 93.68950832365466\n",
      "False Positive Rat: 0.7979274611398963\n",
      "Specificity: 99.20207253886011\n",
      "Precision: 77.73851590106007\n",
      "Prevalence: 2.888195632484653\n",
      "0.7773851590106007\n",
      "0.9981116774791473\n"
     ]
    }
   ],
   "source": [
    "confusion(mnb_model, x_testcv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn:258594 fp:535\n",
      "fn:366 tp:8804\n",
      "\n",
      "Accuracy: 99.66418063429234\n",
      "Misclassification: 0.33581936570766197\n",
      "True Positive Rate: 96.00872410032716\n",
      "False Positive Rat: 0.206460874699474\n",
      "Specificity: 99.79353912530053\n",
      "Precision: 94.27133526073456\n",
      "Prevalence: 3.417828616580755\n",
      "0.9427133526073456\n",
      "0.9985866543095459\n"
     ]
    }
   ],
   "source": [
    "confusion(linear_svc_model, x_testcv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn:258603 fp:690\n",
      "fn:357 tp:8649\n",
      "\n",
      "Accuracy: 99.60976373374481\n",
      "Misclassification: 0.3902362662551854\n",
      "True Positive Rate: 96.03597601598933\n",
      "False Positive Rat: 0.26610822505813886\n",
      "Specificity: 99.73389177494187\n",
      "Precision: 92.61162865403148\n",
      "Prevalence: 3.356702783089016\n",
      "0.9261162865403149\n",
      "0.9986214087117702\n"
     ]
    }
   ],
   "source": [
    "confusion(logistic_model, x_testcv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
